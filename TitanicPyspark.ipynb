{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.16.2.71:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# python dependencies\n",
    "import pandas as pd\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pyspark dependencies\n",
    "from pyspark.sql import functions as func\n",
    "from pyspark.sql.functions import regexp_extract\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Reading the dataset: Training and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male| 22|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female| 38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female| 26|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female| 35|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male| 35|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------+------+--------------------+------+----+-----+-----+-------+-------+-----+--------+\n",
      "|PassengerId|Pclass|                Name|   Sex| Age|SibSp|Parch| Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+------+--------------------+------+----+-----+-----+-------+-------+-----+--------+\n",
      "|        892|     3|    Kelly, Mr. James|  male|34.5|    0|    0| 330911| 7.8292| null|       Q|\n",
      "|        893|     3|Wilkes, Mrs. Jame...|female|  47|    1|    0| 363272|      7| null|       S|\n",
      "|        894|     2|Myles, Mr. Thomas...|  male|  62|    0|    0| 240276| 9.6875| null|       Q|\n",
      "|        895|     3|    Wirz, Mr. Albert|  male|  27|    0|    0| 315154| 8.6625| null|       S|\n",
      "|        896|     3|Hirvonen, Mrs. Al...|female|  22|    1|    1|3101298|12.2875| null|       S|\n",
      "+-----------+------+--------------------+------+----+-----+-----+-------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reading files\n",
    "train_path = 'titanic_train.csv'\n",
    "test_path  = 'titanic_test.csv'\n",
    "\n",
    "train_df = spark.read.format('csv').option('header', 'true').load(train_path)\n",
    "test_df  = spark.read.format('csv').option('header', 'true').load(test_path)\n",
    "\n",
    "train_df.show(5)\n",
    "test_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Survived: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- SibSp: string (nullable = true)\n",
      " |-- Parch: string (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- SibSp: string (nullable = true)\n",
      " |-- Parch: string (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print schema for both train and test dataset\n",
    "train_df.printSchema()\n",
    "test_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Survived: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- SibSp: string (nullable = true)\n",
      " |-- Parch: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- SibSp: string (nullable = true)\n",
      " |-- Parch: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop Ticket and Cabin columns\n",
    "train_droppedCT = train_df.drop('Ticket', 'Cabin')\n",
    "test_droppedCT  = test_df.drop('Ticket', 'Cabin')\n",
    "\n",
    "# Verify columns are dropped by printing the schema\n",
    "train_droppedCT.printSchema()\n",
    "test_droppedCT.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- AgeC: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- AgeC: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cast numeric types\n",
    "train_fare = train_droppedCT.withColumn('Fare', train_droppedCT['Fare'].cast('double'))\n",
    "test_fare  = test_droppedCT.withColumn('Fare', test_droppedCT['Fare'].cast('double'))\n",
    "\n",
    "train_sibsp = train_fare.withColumn('SibSp', train_fare['SibSp'].cast('int'))\n",
    "test_sibsp  = test_fare.withColumn('SibSp', test_fare['SibSp'].cast('int'))\n",
    "\n",
    "train_parch = train_sibsp.withColumn('Parch', train_sibsp['Parch'].cast('int'))\n",
    "test_parch  = test_sibsp.withColumn('Parch', test_sibsp['Parch'].cast('int'))\n",
    "\n",
    "train_casted = train_parch.withColumn('PassengerId', train_droppedCT['PassengerId'].cast('int'))\n",
    "test_casted  = test_parch.withColumn('PassengerId', test_droppedCT['PassengerId'].cast('int'))\n",
    "\n",
    "train_agecasted = train_casted.withColumn('AgeC', train_droppedCT['Age'].cast('double')).drop('Age')\n",
    "test_agecasted  = test_casted.withColumn('AgeC', test_droppedCT['Age'].cast('double')).drop('Age')\n",
    "\n",
    "train_agecasted.printSchema()\n",
    "test_agecasted.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+-----+-----+-------+--------+----+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|SibSp|Parch|   Fare|Embarked|AgeC|\n",
      "+-----------+--------+------+--------------------+------+-----+-----+-------+--------+----+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|    1|    0|   7.25|       S|22.0|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|    1|    0|71.2833|       C|38.0|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|    0|    0|  7.925|       S|26.0|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|    1|    0|   53.1|       S|35.0|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|    0|    0|   8.05|       S|35.0|\n",
      "+-----------+--------+------+--------------------+------+-----+-----+-------+--------+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------+------+--------------------+------+-----+-----+-------+--------+----+\n",
      "|PassengerId|Pclass|                Name|   Sex|SibSp|Parch|   Fare|Embarked|AgeC|\n",
      "+-----------+------+--------------------+------+-----+-----+-------+--------+----+\n",
      "|        892|     3|    Kelly, Mr. James|  male|    0|    0| 7.8292|       Q|34.5|\n",
      "|        893|     3|Wilkes, Mrs. Jame...|female|    1|    0|    7.0|       S|47.0|\n",
      "|        894|     2|Myles, Mr. Thomas...|  male|    0|    0| 9.6875|       Q|62.0|\n",
      "|        895|     3|    Wirz, Mr. Albert|  male|    0|    0| 8.6625|       S|27.0|\n",
      "|        896|     3|Hirvonen, Mrs. Al...|female|    1|    1|12.2875|       S|22.0|\n",
      "+-----------+------+--------------------+------+-----+-----+-------+--------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fill null values for Embarked and AgeC\n",
    "train_filled = train_agecasted.na.fill({'Embarked':'S', 'AgeC':-0.5})\n",
    "test_filled  = test_agecasted.na.fill({'Embarked':'S', 'AgeC':-0.5})\n",
    "\n",
    "train_filled.show(5)\n",
    "test_filled.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Prefix in Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\spark-2.2.0-bin-hadoop2.7\\python\\pyspark\\sql\\dataframe.py:1431: UserWarning: to_replace is a dict and value is not None. value will be ignored.\n",
      "  warnings.warn(\"to_replace is a dict and value is not None. value will be ignored.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Prefix|count|\n",
      "+------+-----+\n",
      "|  Miss|  185|\n",
      "|Master|   40|\n",
      "|    Mr|  517|\n",
      "| Royal|    3|\n",
      "|   Mrs|  126|\n",
      "|  Rare|   20|\n",
      "+------+-----+\n",
      "\n",
      "+------+-----+\n",
      "|Prefix|count|\n",
      "+------+-----+\n",
      "|  Miss|   79|\n",
      "|Master|   21|\n",
      "|    Mr|  240|\n",
      "|   Mrs|   72|\n",
      "|  Rare|    6|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract Prefix from Names\n",
    "train_prefix = train_filled.withColumn('Prefix', regexp_extract(col('Name'), ' ([A-Za-z]+)\\.', 1))\n",
    "test_prefix = test_filled.withColumn('Prefix', regexp_extract(col('Name'), ' ([A-Za-z]+)\\.', 1))\n",
    "\n",
    "# Prefix cleaning\n",
    "to_replace = {'Capt' : 'Rare',\n",
    "              'Col' :'Rare',\n",
    "              'Don' : 'Rare',\n",
    "              'Dr' : 'Rare',\n",
    "              'Major' : 'Rare',\n",
    "              'Rev' : 'Rare',\n",
    "              'Jonkheer' : 'Rare',\n",
    "              'Dona' : 'Rare',\n",
    "              'Countess' : 'Royal',\n",
    "              'Lady' : 'Royal',\n",
    "              'Sir' : 'Royal',\n",
    "              'Mlle' : 'Miss',\n",
    "              'Ms' : 'Miss',\n",
    "              'Mme' : 'Mrs'}\n",
    "\n",
    "train_prefix_changed = train_prefix.na.replace(to_replace, 1, 'Prefix')\n",
    "test_prefix_changed  = test_prefix.na.replace(to_replace, 1, 'Prefix')\n",
    "\n",
    "train_prefix_changed.groupBy('Prefix').count().show()\n",
    "test_prefix_changed.groupBy('Prefix').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute Age based on Average Age for each Prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|Prefix|         AgeImpute|\n",
      "+------+------------------+\n",
      "|  Miss|17.497297297297298|\n",
      "|Master| 4.066750000000001|\n",
      "|    Mr|24.802707930367504|\n",
      "| Royal|43.333333333333336|\n",
      "|   Mrs|30.892857142857142|\n",
      "|  Rare|            43.575|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Average Age per Prefix\n",
    "avePrefix = train_prefix_changed.groupBy('Prefix').agg(func.avg('AgeC')).withColumnRenamed('avg(AgeC)', 'AgeImpute')\n",
    "avePrefix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = false)\n",
      " |-- AgeC: double (nullable = false)\n",
      " |-- Prefix: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_prefix_changed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Prefix: string (nullable = true)\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = false)\n",
      " |-- AgeC: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- Prefix: string (nullable = true)\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = false)\n",
      " |-- AgeC: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# impute age for null ages\n",
    "train_imputedAges = train_prefix_changed.filter(train_prefix_changed.AgeC == -0.5)\\\n",
    "                                        .join(avePrefix, \"Prefix\")\\\n",
    "                                        .drop('AgeC')\\\n",
    "                                        .withColumnRenamed('AgeImpute','AgeC')\n",
    "test_imputedAges  = test_prefix_changed.filter(test_prefix_changed.AgeC == -0.5)\\\n",
    "                                        .join(avePrefix, \"Prefix\")\\\n",
    "                                        .drop('AgeC')\\\n",
    "                                        .withColumnRenamed('AgeImpute','AgeC')\n",
    "\n",
    "train_imputedAges.printSchema()\n",
    "test_imputedAges.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------------+----+------+-----+-----+-------+--------+------+--------+\n",
      "|PassengerId|Prefix|                Name|AgeC|   Sex|SibSp|Parch|   Fare|Embarked|Pclass|Survived|\n",
      "+-----------+------+--------------------+----+------+-----+-----+-------+--------+------+--------+\n",
      "|          1|    Mr|Braund, Mr. Owen ...|22.0|  male|    1|    0|   7.25|       S|     3|       0|\n",
      "|          2|   Mrs|Cumings, Mrs. Joh...|38.0|female|    1|    0|71.2833|       C|     1|       1|\n",
      "|          3|  Miss|Heikkinen, Miss. ...|26.0|female|    0|    0|  7.925|       S|     3|       1|\n",
      "|          4|   Mrs|Futrelle, Mrs. Ja...|35.0|female|    1|    0|   53.1|       S|     1|       1|\n",
      "|          5|    Mr|Allen, Mr. Willia...|35.0|  male|    0|    0|   8.05|       S|     3|       0|\n",
      "+-----------+------+--------------------+----+------+-----+-----+-------+--------+------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------+------+--------------------+----+------+-----+-----+-------+--------+------+\n",
      "|PassengerId|Prefix|                Name|AgeC|   Sex|SibSp|Parch|   Fare|Embarked|Pclass|\n",
      "+-----------+------+--------------------+----+------+-----+-----+-------+--------+------+\n",
      "|        892|    Mr|    Kelly, Mr. James|34.5|  male|    0|    0| 7.8292|       Q|     3|\n",
      "|        893|   Mrs|Wilkes, Mrs. Jame...|47.0|female|    1|    0|    7.0|       S|     3|\n",
      "|        894|    Mr|Myles, Mr. Thomas...|62.0|  male|    0|    0| 9.6875|       Q|     2|\n",
      "|        895|    Mr|    Wirz, Mr. Albert|27.0|  male|    0|    0| 8.6625|       S|     3|\n",
      "|        896|   Mrs|Hirvonen, Mrs. Al...|22.0|female|    1|    1|12.2875|       S|     3|\n",
      "+-----------+------+--------------------+----+------+-----+-----+-------+--------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# union all: imputedAges and nonImputedAges\n",
    "train_arrange = train_imputedAges.select('PassengerId', 'Prefix', 'Name', 'AgeC', \\\n",
    "                                        'Sex', 'SibSp', 'Parch', 'Fare', \\\n",
    "                                        'Embarked', 'Pclass', 'Survived')\n",
    "train_non_null_age = train_prefix_changed.filter(train_prefix_changed.AgeC!=-0.5).select('PassengerId', 'Prefix', 'Name', 'AgeC', \\\n",
    "                                        'Sex', 'SibSp', 'Parch', 'Fare', \\\n",
    "                                        'Embarked', 'Pclass', 'Survived')\n",
    "\n",
    "test_arrange = test_imputedAges.select('PassengerId', 'Prefix', 'Name', 'AgeC', \\\n",
    "                                        'Sex', 'SibSp', 'Parch', 'Fare', \\\n",
    "                                        'Embarked', 'Pclass')\n",
    "test_non_null_age = test_prefix_changed.filter(test_prefix_changed.AgeC!=-0.5).select('PassengerId', 'Prefix', 'Name', 'AgeC', \\\n",
    "                                        'Sex', 'SibSp', 'Parch', 'Fare', \\\n",
    "                                        'Embarked', 'Pclass')\n",
    "\n",
    "train_df1 = train_arrange.union(train_non_null_age).orderBy('PassengerId')\n",
    "test_df1  = test_arrange.union(test_non_null_age).orderBy('PassengerId')\n",
    "\n",
    "train_df1.show(5)\n",
    "test_df1.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoder for all categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OHE(df, catcol):\n",
    "    strIndexer = StringIndexer(inputCol=catcol, outputCol=catcol+'Index')\n",
    "    model = strIndexer.fit(df)\n",
    "    indexed = model.transform(df)\n",
    "    \n",
    "    encoder = OneHotEncoder(inputCol=catcol+'Index', outputCol=catcol+'Vec')\n",
    "    encoded = encoder.transform(indexed)\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------------+----+------+-----+-----+-------+--------+------+--------+-----------+-------------+\n",
      "|PassengerId|Prefix|                Name|AgeC|   Sex|SibSp|Parch|   Fare|Embarked|Pclass|Survived|PrefixIndex|    PrefixVec|\n",
      "+-----------+------+--------------------+----+------+-----+-----+-------+--------+------+--------+-----------+-------------+\n",
      "|          1|    Mr|Braund, Mr. Owen ...|22.0|  male|    1|    0|   7.25|       S|     3|       0|        0.0|(5,[0],[1.0])|\n",
      "|          2|   Mrs|Cumings, Mrs. Joh...|38.0|female|    1|    0|71.2833|       C|     1|       1|        2.0|(5,[2],[1.0])|\n",
      "|          3|  Miss|Heikkinen, Miss. ...|26.0|female|    0|    0|  7.925|       S|     3|       1|        1.0|(5,[1],[1.0])|\n",
      "|          4|   Mrs|Futrelle, Mrs. Ja...|35.0|female|    1|    0|   53.1|       S|     1|       1|        2.0|(5,[2],[1.0])|\n",
      "|          5|    Mr|Allen, Mr. Willia...|35.0|  male|    0|    0|   8.05|       S|     3|       0|        0.0|(5,[0],[1.0])|\n",
      "+-----------+------+--------------------+----+------+-----+-----+-------+--------+------+--------+-----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical      = ['Prefix', 'Sex', 'Embarked', 'Pclass']\n",
    "train_ohe_prefix = OHE(train_df1, 'Prefix')\n",
    "train_ohe_prefix.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ohe_sex      = OHE(train_ohe_prefix, 'Sex')\n",
    "train_ohe_embarked = OHE(train_ohe_sex, 'Embarked')\n",
    "train_ohe_pclass   = OHE(train_ohe_embarked, 'Pclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------------+----+------+-----+-----+-------+--------+------+--------+-----------+-------------+--------+-------------+-------------+-------------+-----------+-------------+\n",
      "|PassengerId|Prefix|                Name|AgeC|   Sex|SibSp|Parch|   Fare|Embarked|Pclass|Survived|PrefixIndex|    PrefixVec|SexIndex|       SexVec|EmbarkedIndex|  EmbarkedVec|PclassIndex|    PclassVec|\n",
      "+-----------+------+--------------------+----+------+-----+-----+-------+--------+------+--------+-----------+-------------+--------+-------------+-------------+-------------+-----------+-------------+\n",
      "|          1|    Mr|Braund, Mr. Owen ...|22.0|  male|    1|    0|   7.25|       S|     3|       0|        0.0|(5,[0],[1.0])|     0.0|(1,[0],[1.0])|          0.0|(2,[0],[1.0])|        0.0|(2,[0],[1.0])|\n",
      "|          2|   Mrs|Cumings, Mrs. Joh...|38.0|female|    1|    0|71.2833|       C|     1|       1|        2.0|(5,[2],[1.0])|     1.0|    (1,[],[])|          1.0|(2,[1],[1.0])|        1.0|(2,[1],[1.0])|\n",
      "|          3|  Miss|Heikkinen, Miss. ...|26.0|female|    0|    0|  7.925|       S|     3|       1|        1.0|(5,[1],[1.0])|     1.0|    (1,[],[])|          0.0|(2,[0],[1.0])|        0.0|(2,[0],[1.0])|\n",
      "|          4|   Mrs|Futrelle, Mrs. Ja...|35.0|female|    1|    0|   53.1|       S|     1|       1|        2.0|(5,[2],[1.0])|     1.0|    (1,[],[])|          0.0|(2,[0],[1.0])|        1.0|(2,[1],[1.0])|\n",
      "|          5|    Mr|Allen, Mr. Willia...|35.0|  male|    0|    0|   8.05|       S|     3|       0|        0.0|(5,[0],[1.0])|     0.0|(1,[0],[1.0])|          0.0|(2,[0],[1.0])|        0.0|(2,[0],[1.0])|\n",
      "+-----------+------+--------------------+----+------+-----+-----+-------+--------+------+--------+-----------+-------------+--------+-------------+-------------+-------------+-----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_ohe_pclass.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Prefix',\n",
       " 'Name',\n",
       " 'AgeC',\n",
       " 'Sex',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Fare',\n",
       " 'Embarked',\n",
       " 'Pclass',\n",
       " 'Survived',\n",
       " 'PrefixIndex',\n",
       " 'PrefixVec',\n",
       " 'SexIndex',\n",
       " 'SexVec',\n",
       " 'EmbarkedIndex',\n",
       " 'EmbarkedVec',\n",
       " 'PclassIndex',\n",
       " 'PclassVec']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ohe_pclass.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a StringIndexer for the target variable\n",
    "labelIndexer  = StringIndexer(inputCol='Survived', outputCol='SurvivedNum')\n",
    "labelIndmodel = labelIndexer.fit(train_ohe_pclass)\n",
    "labelIndexed  = labelIndmodel.transform(train_ohe_pclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an Assembler\n",
    "numeric   = ['AgeC', 'SibSp', 'Parch', 'Fare']\n",
    "asseInp   = [c + 'Vec' for c in categorical] + numeric\n",
    "assembler = VectorAssembler(inputCols=asseInp, outputCol='features')\n",
    "assembtra = assembler.transform(labelIndexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------------+------------------+------+-----+-----+-------+--------+------+--------+-----------+-------------+--------+-------------+-------------+-------------+-----------+-------------+-----------+--------------------+\n",
      "|PassengerId|Prefix|                Name|              AgeC|   Sex|SibSp|Parch|   Fare|Embarked|Pclass|Survived|PrefixIndex|    PrefixVec|SexIndex|       SexVec|EmbarkedIndex|  EmbarkedVec|PclassIndex|    PclassVec|SurvivedNum|            features|\n",
      "+-----------+------+--------------------+------------------+------+-----+-----+-------+--------+------+--------+-----------+-------------+--------+-------------+-------------+-------------+-----------+-------------+-----------+--------------------+\n",
      "|          1|    Mr|Braund, Mr. Owen ...|              22.0|  male|    1|    0|   7.25|       S|     3|       0|        0.0|(5,[0],[1.0])|     0.0|(1,[0],[1.0])|          0.0|(2,[0],[1.0])|        0.0|(2,[0],[1.0])|        0.0|(14,[0,5,6,8,10,1...|\n",
      "|          2|   Mrs|Cumings, Mrs. Joh...|              38.0|female|    1|    0|71.2833|       C|     1|       1|        2.0|(5,[2],[1.0])|     1.0|    (1,[],[])|          1.0|(2,[1],[1.0])|        1.0|(2,[1],[1.0])|        1.0|(14,[2,7,9,10,11,...|\n",
      "|          3|  Miss|Heikkinen, Miss. ...|              26.0|female|    0|    0|  7.925|       S|     3|       1|        1.0|(5,[1],[1.0])|     1.0|    (1,[],[])|          0.0|(2,[0],[1.0])|        0.0|(2,[0],[1.0])|        1.0|(14,[1,6,8,10,13]...|\n",
      "|          4|   Mrs|Futrelle, Mrs. Ja...|              35.0|female|    1|    0|   53.1|       S|     1|       1|        2.0|(5,[2],[1.0])|     1.0|    (1,[],[])|          0.0|(2,[0],[1.0])|        1.0|(2,[1],[1.0])|        1.0|(14,[2,6,9,10,11,...|\n",
      "|          5|    Mr|Allen, Mr. Willia...|              35.0|  male|    0|    0|   8.05|       S|     3|       0|        0.0|(5,[0],[1.0])|     0.0|(1,[0],[1.0])|          0.0|(2,[0],[1.0])|        0.0|(2,[0],[1.0])|        0.0|(14,[0,5,6,8,10,1...|\n",
      "|          6|    Mr|    Moran, Mr. James|24.802707930367504|  male|    0|    0| 8.4583|       Q|     3|       0|        0.0|(5,[0],[1.0])|     0.0|(1,[0],[1.0])|          2.0|    (2,[],[])|        0.0|(2,[0],[1.0])|        0.0|(14,[0,5,8,10,13]...|\n",
      "|          7|    Mr|McCarthy, Mr. Tim...|              54.0|  male|    0|    0|51.8625|       S|     1|       0|        0.0|(5,[0],[1.0])|     0.0|(1,[0],[1.0])|          0.0|(2,[0],[1.0])|        1.0|(2,[1],[1.0])|        0.0|(14,[0,5,6,9,10,1...|\n",
      "|          8|Master|Palsson, Master. ...|               2.0|  male|    3|    1| 21.075|       S|     3|       0|        3.0|(5,[3],[1.0])|     0.0|(1,[0],[1.0])|          0.0|(2,[0],[1.0])|        0.0|(2,[0],[1.0])|        0.0|(14,[3,5,6,8,10,1...|\n",
      "|          9|   Mrs|Johnson, Mrs. Osc...|              27.0|female|    0|    2|11.1333|       S|     3|       1|        2.0|(5,[2],[1.0])|     1.0|    (1,[],[])|          0.0|(2,[0],[1.0])|        0.0|(2,[0],[1.0])|        1.0|(14,[2,6,8,10,12,...|\n",
      "|         10|   Mrs|Nasser, Mrs. Nich...|              14.0|female|    1|    0|30.0708|       C|     2|       1|        2.0|(5,[2],[1.0])|     1.0|    (1,[],[])|          1.0|(2,[1],[1.0])|        2.0|    (2,[],[])|        1.0|(14,[2,7,10,11,13...|\n",
      "|         11|  Miss|Sandstrom, Miss. ...|               4.0|female|    1|    1|   16.7|       S|     3|       1|        1.0|(5,[1],[1.0])|     1.0|    (1,[],[])|          0.0|(2,[0],[1.0])|        0.0|(2,[0],[1.0])|        1.0|(14,[1,6,8,10,11,...|\n",
      "|         12|  Miss|Bonnell, Miss. El...|              58.0|female|    0|    0|  26.55|       S|     1|       1|        1.0|(5,[1],[1.0])|     1.0|    (1,[],[])|          0.0|(2,[0],[1.0])|        1.0|(2,[1],[1.0])|        1.0|(14,[1,6,9,10,13]...|\n",
      "|         13|    Mr|Saundercock, Mr. ...|              20.0|  male|    0|    0|   8.05|       S|     3|       0|        0.0|(5,[0],[1.0])|     0.0|(1,[0],[1.0])|          0.0|(2,[0],[1.0])|        0.0|(2,[0],[1.0])|        0.0|(14,[0,5,6,8,10,1...|\n",
      "|         14|    Mr|Andersson, Mr. An...|              39.0|  male|    1|    5| 31.275|       S|     3|       0|        0.0|(5,[0],[1.0])|     0.0|(1,[0],[1.0])|          0.0|(2,[0],[1.0])|        0.0|(2,[0],[1.0])|        0.0|(14,[0,5,6,8,10,1...|\n",
      "|         15|  Miss|Vestrom, Miss. Hu...|              14.0|female|    0|    0| 7.8542|       S|     3|       0|        1.0|(5,[1],[1.0])|     1.0|    (1,[],[])|          0.0|(2,[0],[1.0])|        0.0|(2,[0],[1.0])|        0.0|(14,[1,6,8,10,13]...|\n",
      "|         16|   Mrs|Hewlett, Mrs. (Ma...|              55.0|female|    0|    0|   16.0|       S|     2|       1|        2.0|(5,[2],[1.0])|     1.0|    (1,[],[])|          0.0|(2,[0],[1.0])|        2.0|    (2,[],[])|        1.0|(14,[2,6,10,13],[...|\n",
      "|         17|Master|Rice, Master. Eugene|               2.0|  male|    4|    1| 29.125|       Q|     3|       0|        3.0|(5,[3],[1.0])|     0.0|(1,[0],[1.0])|          2.0|    (2,[],[])|        0.0|(2,[0],[1.0])|        0.0|(14,[3,5,8,10,11,...|\n",
      "|         18|    Mr|Williams, Mr. Cha...|24.802707930367504|  male|    0|    0|   13.0|       S|     2|       1|        0.0|(5,[0],[1.0])|     0.0|(1,[0],[1.0])|          0.0|(2,[0],[1.0])|        2.0|    (2,[],[])|        1.0|(14,[0,5,6,10,13]...|\n",
      "|         19|   Mrs|Vander Planke, Mr...|              31.0|female|    1|    0|   18.0|       S|     3|       0|        2.0|(5,[2],[1.0])|     1.0|    (1,[],[])|          0.0|(2,[0],[1.0])|        0.0|(2,[0],[1.0])|        0.0|(14,[2,6,8,10,11,...|\n",
      "|         20|   Mrs|Masselmani, Mrs. ...|30.892857142857142|female|    0|    0|  7.225|       C|     3|       1|        2.0|(5,[2],[1.0])|     1.0|    (1,[],[])|          1.0|(2,[1],[1.0])|        0.0|(2,[0],[1.0])|        1.0|(14,[2,7,8,10,13]...|\n",
      "+-----------+------+--------------------+------------------+------+-----+-----+-------+--------+------+--------+-----------+-------------+--------+-------------+-------------+-------------+-----------+-------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembtra.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select columns to use\n",
    "selected = ['PassengerId', 'SurvivedNum', 'features']\n",
    "dataset  = assembtra.select(selected)\n",
    "dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610\n",
      "281\n"
     ]
    }
   ],
   "source": [
    "# RandomSplit for training and Validation\n",
    "training, validation = dataset.randomSplit([0.7, 0.3], seed=100)\n",
    "print training.count()\n",
    "print validation.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+--------------------+\n",
      "|PassengerId|SurvivedNum|            features|\n",
      "+-----------+-----------+--------------------+\n",
      "|          1|        0.0|(14,[0,5,6,8,10,1...|\n",
      "|          2|        1.0|(14,[2,7,9,10,11,...|\n",
      "|          3|        1.0|(14,[1,6,8,10,13]...|\n",
      "|          4|        1.0|(14,[2,6,9,10,11,...|\n",
      "|          6|        0.0|(14,[0,5,8,10,13]...|\n",
      "+-----------+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+--------------------+\n",
      "|PassengerId|SurvivedNum|            features|\n",
      "+-----------+-----------+--------------------+\n",
      "|          5|        0.0|(14,[0,5,6,8,10,1...|\n",
      "|         11|        1.0|(14,[1,6,8,10,11,...|\n",
      "|         13|        0.0|(14,[0,5,6,8,10,1...|\n",
      "|         15|        0.0|(14,[1,6,8,10,13]...|\n",
      "|         16|        1.0|(14,[2,6,10,13],[...|\n",
      "+-----------+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validation.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients : [-0.998675305167,1.57041700576,2.36220663072,3.46972644055,-0.947308320335,-0.521249601961,0.408436694135,0.783011031359,-0.969890573489,0.874650131679,-0.0106414947916,-0.658283083915,-0.433255618467,0.00429524460515]\n",
      "Intercept : -0.0387130998414\n"
     ]
    }
   ],
   "source": [
    "lr      = LogisticRegression(labelCol='SurvivedNum', featuresCol='features', maxIter=10)\n",
    "lrmodel = lr.fit(training)\n",
    "print \"Coefficients : \" + str(lrmodel.coefficients)\n",
    "print \"Intercept : \" + str(lrmodel.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- SurvivedNum: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n",
      "+-----------+-----------+--------------------+--------------------+--------------------+----------+\n",
      "|PassengerId|SurvivedNum|            features|       rawPrediction|         probability|prediction|\n",
      "+-----------+-----------+--------------------+--------------------+--------------------+----------+\n",
      "|          5|        0.0|(14,[0,5,6,8,10,1...|[2.45796748495796...|[0.92114214869829...|       0.0|\n",
      "|         11|        1.0|(14,[1,6,8,10,11,...|[0.09212407007966...|[0.52301474294346...|       0.0|\n",
      "|         13|        0.0|(14,[0,5,6,8,10,1...|[2.29834506308375...|[0.90873988505028...|       0.0|\n",
      "|         15|        0.0|(14,[1,6,8,10,13]...|[-0.8550048096577...|[0.29838403947695...|       1.0|\n",
      "|         16|        1.0|(14,[2,6,10,13],[...|[-2.2153719251562...|[0.09837855317847...|       1.0|\n",
      "+-----------+-----------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions for validation set\n",
    "val_pred = lrmodel.transform(validation)\n",
    "val_pred.printSchema()\n",
    "val_pred.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='SurvivedNum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7875369822485206"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+--------------------+--------------------+--------------------+----------+----+\n",
      "|PassengerId|SurvivedNum|            features|       rawPrediction|         probability|prediction|Diff|\n",
      "+-----------+-----------+--------------------+--------------------+--------------------+----------+----+\n",
      "|          5|        0.0|(14,[0,5,6,8,10,1...|[2.45796748495796...|[0.92114214869829...|       0.0| 0.0|\n",
      "|         11|        1.0|(14,[1,6,8,10,11,...|[0.09212407007966...|[0.52301474294346...|       0.0| 1.0|\n",
      "|         13|        0.0|(14,[0,5,6,8,10,1...|[2.29834506308375...|[0.90873988505028...|       0.0| 0.0|\n",
      "|         15|        0.0|(14,[1,6,8,10,13]...|[-0.8550048096577...|[0.29838403947695...|       1.0| 1.0|\n",
      "|         16|        1.0|(14,[2,6,10,13],[...|[-2.2153719251562...|[0.09837855317847...|       1.0| 0.0|\n",
      "+-----------+-----------+--------------------+--------------------+--------------------+----------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "val_pred_diff = val_pred.withColumn('Diff', (col('SurvivedNum') - col('prediction'))**2)\n",
    "val_pred_diff.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8078291814946619"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = 1- val_pred_diff.select('Diff').groupBy().sum().rdd.map(lambda x: x[0]).collect()[0]/281\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+--------------------+--------------------+--------------------+----------+----+\n",
      "|PassengerId|SurvivedNum|            features|       rawPrediction|         probability|prediction|Diff|\n",
      "+-----------+-----------+--------------------+--------------------+--------------------+----------+----+\n",
      "|          5|        0.0|(14,[0,5,6,8,10,1...|[2.22505960051157...|[0.90247740864142...|       0.0| 0.0|\n",
      "|         11|        1.0|(14,[1,6,8,10,11,...|[-0.0609064977009...|[0.48477808088830...|       1.0| 0.0|\n",
      "|         13|        0.0|(14,[0,5,6,8,10,1...|[2.28881957979900...|[0.90794683878190...|       0.0| 0.0|\n",
      "|         15|        0.0|(14,[1,6,8,10,13]...|[-0.4941598988515...|[0.37891409258227...|       1.0| 1.0|\n",
      "|         16|        1.0|(14,[2,6,10,13],[...|[-1.6328337468435...|[0.16344253602646...|       1.0| 0.0|\n",
      "+-----------+-----------+--------------------+--------------------+--------------------+----------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19217081850533807"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01, 0.5])\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.5])\n",
    "             .addGrid(lr.maxIter, [1, 5])\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(training)\n",
    "# this will likely take a fair amount of time because of the amount of models that we're creating and testing\n",
    "\n",
    "# Use test set to measure the accuracy of our model on new data\n",
    "predictions = cvModel.transform(validation)\n",
    "\n",
    "# cvModel uses the best model found from the Cross Validation\n",
    "# Evaluate best model\n",
    "evaluator.evaluate(predictions) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+--------------------+--------------------+--------------------+----------+----+\n",
      "|PassengerId|SurvivedNum|            features|       rawPrediction|         probability|prediction|Diff|\n",
      "+-----------+-----------+--------------------+--------------------+--------------------+----------+----+\n",
      "|          5|        0.0|(14,[0,5,6,8,10,1...|[2.22505960051157...|[0.90247740864142...|       0.0| 0.0|\n",
      "|         11|        1.0|(14,[1,6,8,10,11,...|[-0.0609064977009...|[0.48477808088830...|       1.0| 0.0|\n",
      "|         13|        0.0|(14,[0,5,6,8,10,1...|[2.28881957979900...|[0.90794683878190...|       0.0| 0.0|\n",
      "|         15|        0.0|(14,[1,6,8,10,13]...|[-0.4941598988515...|[0.37891409258227...|       1.0| 1.0|\n",
      "|         16|        1.0|(14,[2,6,10,13],[...|[-1.6328337468435...|[0.16344253602646...|       1.0| 0.0|\n",
      "+-----------+-----------+--------------------+--------------------+--------------------+----------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8078291814946619"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "best_pred_diff = predictions.withColumn('Diff', (col('SurvivedNum') - col('prediction'))**2)\n",
    "best_pred_diff.show(5)\n",
    "accuracy_best = 1 - best_pred_diff.select('Diff').groupBy().sum().rdd.map(lambda x: x[0]).collect()[0]/281\n",
    "accuracy_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(labelCol='SurvivedNum', featuresCol='features', maxDepth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+--------------------+-------------+--------------------+----------+\n",
      "|PassengerId|SurvivedNum|            features|rawPrediction|         probability|prediction|\n",
      "+-----------+-----------+--------------------+-------------+--------------------+----------+\n",
      "|          5|        0.0|(14,[0,5,6,8,10,1...| [257.0,30.0]|[0.89547038327526...|       0.0|\n",
      "|         11|        1.0|(14,[1,6,8,10,11,...|  [59.0,52.0]|[0.53153153153153...|       0.0|\n",
      "|         13|        0.0|(14,[0,5,6,8,10,1...| [257.0,30.0]|[0.89547038327526...|       0.0|\n",
      "|         15|        0.0|(14,[1,6,8,10,13]...|  [59.0,52.0]|[0.53153153153153...|       0.0|\n",
      "|         16|        1.0|(14,[2,6,10,13],[...| [14.0,124.0]|[0.10144927536231...|       1.0|\n",
      "|         18|        1.0|(14,[0,5,6,10,13]...| [257.0,30.0]|[0.89547038327526...|       0.0|\n",
      "|         26|        1.0|(14,[2,6,8,10,11,...|  [59.0,52.0]|[0.53153153153153...|       0.0|\n",
      "|         28|        0.0|(14,[0,5,6,9,10,1...|  [50.0,24.0]|[0.67567567567567...|       0.0|\n",
      "|         30|        0.0|(14,[0,5,6,8,10,1...| [257.0,30.0]|[0.89547038327526...|       0.0|\n",
      "|         32|        1.0|(14,[2,7,9,10,11,...| [14.0,124.0]|[0.10144927536231...|       1.0|\n",
      "|         33|        1.0|(14,[1,8,10,13],[...|  [59.0,52.0]|[0.53153153153153...|       0.0|\n",
      "|         34|        0.0|(14,[0,5,6,10,13]...| [257.0,30.0]|[0.89547038327526...|       0.0|\n",
      "|         40|        1.0|(14,[1,7,8,10,11,...|  [59.0,52.0]|[0.53153153153153...|       0.0|\n",
      "|         45|        1.0|(14,[1,8,10,13],[...|  [59.0,52.0]|[0.53153153153153...|       0.0|\n",
      "|         49|        0.0|(14,[0,5,7,8,10,1...| [257.0,30.0]|[0.89547038327526...|       0.0|\n",
      "|         50|        0.0|(14,[2,6,8,10,11,...|  [59.0,52.0]|[0.53153153153153...|       0.0|\n",
      "|         56|        1.0|(14,[0,5,6,9,10,1...|  [50.0,24.0]|[0.67567567567567...|       0.0|\n",
      "|         62|        1.0|(14,[1,6,9,10,13]...| [14.0,124.0]|[0.10144927536231...|       1.0|\n",
      "|         64|        0.0|(14,[3,5,6,8,10,1...|  [59.0,52.0]|[0.53153153153153...|       0.0|\n",
      "|         65|        0.0|(14,[0,5,7,9,10,1...|  [50.0,24.0]|[0.67567567567567...|       0.0|\n",
      "+-----------+-----------+--------------------+-------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtcmodel = dtc.fit(training)\n",
    "dtc_pred = dtcmodel.transform(validation)\n",
    "dtc_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7580071174377224"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_diff = dtc_pred.withColumn('Diff', (col('SurvivedNum')-col('prediction'))**2)\n",
    "dtc_accuracy = 1 - dtc_diff.select('Diff').groupBy().sum().rdd.map(lambda x: x[0]).collect()[0]/281\n",
    "dtc_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7651245551601423"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(numTrees=3, maxDepth=2, labelCol='SurvivedNum', featuresCol='features', seed=42)\n",
    "rfc_model = rfc.fit(training)\n",
    "rfc_pred  = rfc_model.transform(validation)\n",
    "rfc_diff  = rfc_pred.withColumn('Diff', (col('SurvivedNum')-col('prediction'))**2)\n",
    "rfc_accuracy = 1 - rfc_diff.select('Diff').groupBy().sum().rdd.map(lambda x: x[0]).collect()[0]/281\n",
    "rfc_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.8078291814946619\n",
      "Best LR: 0.8078291814946619\n",
      "Random Forest: 0.7651245551601423\n",
      "Decision Trees: 0.7580071174377224\n"
     ]
    }
   ],
   "source": [
    "# print 'Accuracy:'\n",
    "print 'Logistic Regression: ' + `accuracy`\n",
    "print 'Best LR: ' + `accuracy_best`\n",
    "print 'Random Forest: ' + `rfc_accuracy`\n",
    "print 'Decision Trees: ' + `dtc_accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
